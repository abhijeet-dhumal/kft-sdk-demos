{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0223daea-31a5-441b-ae6e-671be1c3a047",
   "metadata": {},
   "source": [
    "## MNIST Distributed Training\n",
    "\n",
    "### Overview\n",
    "Distributed training of a CNN model on MNIST handwritten digit dataset using PyTorch's DistributedDataParallel (DDP).\n",
    "### Training Setup\n",
    "- **Backend**: NCCL (GPU) / Gloo (CPU)\n",
    "- **Data**: MNIST test set (train=False)\n",
    "- **Distributed**: Multi-Node Multi-CPU/GPU with DistributedSampler\n",
    "- **Device Flexibility**: Auto-fallback GPU→CPU\n",
    "### Key Parameters\n",
    "- `epochs`: Training iterations\n",
    "- `batch_size`: Samples per device\n",
    "- `lr`: Learning rate\n",
    "- `save_every`: Checkpoint frequency\n",
    "- `backend`: Communication backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af90293f-c2fa-4a18-aed6-930bf2e4a03d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install kubeflow\n",
    "%pip install -U kubeflow-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61425b7b-9133-4c12-95d1-9462ab131095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: kubeflow-training\n",
      "Version: 1.9.3\n",
      "Summary: Training Operator Python SDK\n",
      "Home-page: https://github.com/kubeflow/training-operator/tree/master/sdk/python\n",
      "Author: Kubeflow Authors\n",
      "Author-email: hejinchi@cn.ibm.com\n",
      "License: Apache License Version 2.0\n",
      "Location: /opt/app-root/lib64/python3.12/site-packages\n",
      "Requires: certifi, kubernetes, retrying, setuptools, six, urllib3\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show kubeflow-training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034f4da3-82d0-4110-984b-e5d1ef2041bc",
   "metadata": {},
   "source": [
    "### Initialise Training Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33ebf57b-6a7b-41fc-85bb-d9493a415f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully authenticated!\n"
     ]
    }
   ],
   "source": [
    "from kubernetes import client\n",
    "from kubeflow.training import TrainingClient\n",
    "\n",
    "api_server = \"\"\n",
    "token = \"\"\n",
    "\n",
    "# Configure the API client with the server and token\n",
    "configuration = client.Configuration()\n",
    "configuration.host = api_server\n",
    "configuration.api_key = {\"authorization\": f\"Bearer {token}\"}\n",
    "configuration.verify_ssl = False  # Disable SSL verification\n",
    "\n",
    "# Initialize API client and TrainingClient with the configuration\n",
    "api_client = client.ApiClient(configuration)\n",
    "client = TrainingClient(client_configuration=api_client.configuration)\n",
    "\n",
    "print(\"successfully authenticated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdd9bfd-c852-4aa5-939d-ca4e1d81c013",
   "metadata": {},
   "source": [
    "### Submit PytorchJob using Kubeflow-Training SDK to be managed by Kubeflow Trainer V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2040326f-860c-4080-8cda-f9f8dcd18ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Client Initialised !\n"
     ]
    }
   ],
   "source": [
    "from kfto_mnist import main\n",
    "from kubeflow.training.models import V1Volume, V1VolumeMount, V1PersistentVolumeClaimVolumeSource\n",
    "\n",
    "# Start PyTorchJob with 2 Workers and 2 GPU per Worker (e.g. multi-node, multi-worker job).\n",
    "client.create_job(\n",
    "    name=\"pytorch-ddp\",\n",
    "    train_func=main,\n",
    "    base_image=\"quay.io/modh/training:py311-cuda121-torch241\",\n",
    "    num_workers=2,\n",
    "    resources_per_worker={\"gpu\": \"1\"},\n",
    "    packages_to_install=[\"torchvision==0.19.0\"],\n",
    "    parameters={\n",
    "       \"epochs\": 5, \n",
    "       \"save_every\": 2, \n",
    "       \"batch_size\": 2, \n",
    "       \"backend\": \"gloo\",\n",
    "       \"lr\" : 0.001, \n",
    "       \"dataset_path\": \"/shared/data\", \n",
    "       'snapshot_path': \"/shared/checkpoints/snapshot_mnist.pt\"\n",
    "    },\n",
    "    env_vars={\n",
    "        \"NCCL_DEBUG\": \"INFO\", \n",
    "        \"TORCH_DISTRIBUTED_DEBUG\": \"DETAIL\",\n",
    "    },\n",
    "    volumes=[\n",
    "        V1Volume(\n",
    "            name=\"shared\",\n",
    "            persistent_volume_claim=V1PersistentVolumeClaimVolumeSource(claim_name=\"shared\")\n",
    "        ),\n",
    "    ],\n",
    "    volume_mounts=[\n",
    "        V1VolumeMount(name=\"shared\", mount_path=\"/shared\"),\n",
    "    ],\n",
    ")\n",
    "print(\"Training Client Initialised !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b614dd6-3669-4503-9da0-5097b781e61c",
   "metadata": {},
   "source": [
    "### Get PytorchJob Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05ab1733-eb5d-45c0-8751-19a2bf3d2431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-ddp-master-0:\n",
      "\n",
      "2025-10-05T14:31:33Z INFO     No GPU available, falling back to CPU.\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /shared/data/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "100%|██████████| 9912422/9912422 [00:00<00:00, 128286441.04it/s]\n",
      "Extracting /shared/data/MNIST/raw/train-images-idx3-ubyte.gz to /shared/data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /shared/data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "100%|██████████| 28881/28881 [00:00<00:00, 25566841.25it/s]\n",
      "Extracting /shared/data/MNIST/raw/train-labels-idx1-ubyte.gz to /shared/data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /shared/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "100%|██████████| 1648877/1648877 [00:00<00:00, 70536491.65it/s]\n",
      "Extracting /shared/data/MNIST/raw/t10k-images-idx3-ubyte.gz to /shared/data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /shared/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "100%|██████████| 4542/4542 [00:00<00:00, 8750817.07it/s]\n",
      "Extracting /shared/data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /shared/data/MNIST/raw\n",
      "\n",
      "2025-10-05T14:31:33Z INFO     Using device: cpu\n",
      "2025-10-05T14:31:33Z INFO     [CPU0] Epoch 0 | Batchsize: 2 | Steps: 2500\n",
      "2025-10-05T14:33:01Z INFO     Epoch 0 | Training snapshot saved at /shared/checkpoints/snapshot_mnist.pt\n",
      "2025-10-05T14:33:01Z INFO     [CPU0] Epoch 1 | Batchsize: 2 | Steps: 2500\n",
      "2025-10-05T14:34:20Z INFO     [CPU0] Epoch 2 | Batchsize: 2 | Steps: 2500\n",
      "2025-10-05T14:35:43Z INFO     Epoch 2 | Training snapshot saved at /shared/checkpoints/snapshot_mnist.pt\n",
      "2025-10-05T14:35:43Z INFO     [CPU0] Epoch 3 | Batchsize: 2 | Steps: 2500\n",
      "2025-10-05T14:37:03Z INFO     [CPU0] Epoch 4 | Batchsize: 2 | Steps: 2500\n",
      "2025-10-05T14:38:23Z INFO     Epoch 4 | Training snapshot saved at /shared/checkpoints/snapshot_mnist.pt\n",
      "\n",
      "PytorchJob succeeded!\n"
     ]
    }
   ],
   "source": [
    "logs= client.get_job_logs(name=\"pytorch-ddp\")\n",
    "print(\"pytorch-ddp-master-0:\\n\\n\"+logs[0]['pytorch-ddp-master-0'])\n",
    "if client.is_job_succeeded(name=\"pytorch-ddp\"):\n",
    "    print(\"PytorchJob succeeded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf62a15a-3202-4239-a7bf-39b466a8c852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting.\n",
      "................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "PytorchJob succeeded!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(\"waiting.\")\n",
    "while not client.is_job_succeeded(name=\"pytorch-ddp\"):\n",
    "    print(\".\", end=\"\")\n",
    "    time.sleep(1)\n",
    "print(\"\\nPytorchJob succeeded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30f3c09-cffe-467d-b48e-b1c43a529b4c",
   "metadata": {},
   "source": [
    "### Cleanup resources created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c3f19c-5aba-4738-8ba2-32a3dc6b15b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PytorchJob deleted gracefully!\n"
     ]
    }
   ],
   "source": [
    "client.delete_job(name=\"pytorch-ddp\", namespace=\"abdhumal-test\")\n",
    "print(\"PytorchJob deleted gracefully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
