{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0223daea-31a5-441b-ae6e-671be1c3a047",
   "metadata": {},
   "source": [
    "## MNIST Distributed Training\n",
    "\n",
    "### Overview\n",
    "Distributed training of a CNN model on MNIST handwritten digit dataset using PyTorch's DistributedDataParallel (DDP).\n",
    "### Training Setup\n",
    "- **Backend**: NCCL (GPU) / Gloo (CPU)\n",
    "- **Data**: MNIST test set (train=False)\n",
    "- **Distributed**: Multi-Node Multi-CPU/GPU with DistributedSampler\n",
    "- **Device Flexibility**: Auto-fallback GPUâ†’CPU\n",
    "### Key Parameters\n",
    "- `epochs`: Training iterations\n",
    "- `batch_size`: Samples per device\n",
    "- `lr`: Learning rate\n",
    "- `save_every`: Checkpoint frequency\n",
    "- `backend`: Communication backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af90293f-c2fa-4a18-aed6-930bf2e4a03d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install dist/kubeflow-0.2.0.dev0-py3-none-any.whl --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61425b7b-9133-4c12-95d1-9462ab131095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: kubeflow\n",
      "Version: 0.1.0\n",
      "Summary: Kubeflow Python SDK to manage ML workloads and to interact with Kubeflow APIs.\n",
      "Home-page: https://github.com/kubeflow/sdk\n",
      "Author: \n",
      "Author-email: The Kubeflow Authors <kubeflow-discuss@googlegroups.com>\n",
      "License: \n",
      "Location: /opt/app-root/lib64/python3.12/site-packages\n",
      "Requires: kubeflow-trainer-api, kubernetes, pydantic\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show kubeflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034f4da3-82d0-4110-984b-e5d1ef2041bc",
   "metadata": {},
   "source": [
    "### Initialize Training Client\n",
    "\n",
    "This section demonstrates the new SDK import structure and client initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ebf57b-6a7b-41fc-85bb-d9493a415f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Trainer client initialized\n",
      "Available runtimes: 4\n",
      "  - torch-cuda-241: torch (1 nodes)\n",
      "  - torch-cuda-251: torch (1 nodes)\n",
      "  - torch-rocm-241: torch (1 nodes)\n",
      "  - torch-rocm-251: torch (1 nodes)\n"
     ]
    }
   ],
   "source": [
    "from kubeflow.trainer import TrainerClient\n",
    "from kubeflow.trainer.backends.kubernetes.types import KubernetesBackendConfig\n",
    "from kubernetes import client\n",
    "\n",
    "# Configure Kubernetes client\n",
    "# Replace with your cluster details\n",
    "api_server = \"\"\n",
    "token = \"\"\n",
    "namespace = \"test-ns\"\n",
    "\n",
    "configuration = client.Configuration()\n",
    "configuration.host = api_server\n",
    "configuration.api_key = {\"authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "# Uncomment if your cluster API server uses a self-signed certificate\n",
    "# configuration.verify_ssl = False\n",
    "\n",
    "api_client = client.ApiClient(configuration)\n",
    "trainer_client = TrainerClient(\n",
    "    backend_config=KubernetesBackendConfig(\n",
    "        namespace=namespace, \n",
    "        client_configuration=api_client.configuration\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"âœ“ Trainer client initialized\")\n",
    "print(f\"Available runtimes: {len(trainer_client.list_runtimes())}\")\n",
    "for runtime in trainer_client.list_runtimes():\n",
    "    print(f\"  ðŸ”§ {runtime.name}: {runtime.trainer.framework} ({runtime.trainer.num_nodes} nodes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdd9bfd-c852-4aa5-939d-ca4e1d81c013",
   "metadata": {},
   "source": [
    "### Submit Training Jobs - Demonstrating New SDK Features\n",
    "\n",
    "This section showcases the new SDK features:\n",
    "1. **Backend-specific imports** for better organization\n",
    "2. **Option 2 features** for container customization\n",
    "3. **Enhanced options** with override behavior\n",
    "4. **Multiple training scenarios** (traditional, hybrid, container-only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c485097-aea3-445b-a17b-1881188383a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubeflow.trainer import CustomTrainer, WithTrainerImage, WithTrainerCommand, WithTrainerArgs\n",
    "\n",
    "# Backend-specific imports\n",
    "from kubeflow.trainer.backends.kubernetes.options import (\n",
    "    WithLabels, WithAnnotations, WithName, WithPodSpecOverrides, PodSpecOverride\n",
    ")\n",
    "\n",
    "# Import the training function\n",
    "from kfto_mnist import main\n",
    "\n",
    "# Traditional approach with enhanced options\n",
    "traditional_trainer = CustomTrainer(\n",
    "    func=main,\n",
    "    func_args={\n",
    "        \"epochs\": 3,\n",
    "        \"save_every\": 1, \n",
    "        \"batch_size\": 4, \n",
    "        \"backend\": \"gloo\",  # CPU backend for demo\n",
    "        \"lr\": 0.001, \n",
    "        \"dataset_path\": \"/shared/data\", \n",
    "        'snapshot_path': \"/shared/checkpoints/snapshot_mnist.pt\"\n",
    "    },\n",
    "    num_nodes=2,\n",
    "    resources_per_node={\n",
    "        \"cpu\": \"2\",\n",
    "        \"memory\": \"4Gi\",\n",
    "    },\n",
    "    packages_to_install=[\"torchvision\"]\n",
    ")\n",
    "\n",
    "# Enhanced options with override behavior\n",
    "traditional_options = [\n",
    "    WithName(\"mnist-traditional-demo\"),\n",
    "    WithLabels({\n",
    "        \"team\": \"ml-platform\",\n",
    "        \"project\": \"training-experiment\",\n",
    "        \"approach\": \"traditional\",\n",
    "        \"sdk-version\": \"0.2.0.dev0\"\n",
    "    }),\n",
    "    WithAnnotations({\n",
    "        \"created-by\": \"kubeflow-sdk-v2\",\n",
    "        \"training-type\": \"function-based\"\n",
    "    }),\n",
    "    WithPodSpecOverrides([\n",
    "        PodSpecOverride(\n",
    "            target_jobs=[\"node\"],\n",
    "            volumes=[{\n",
    "                \"name\": \"shared\",\n",
    "                \"persistentVolumeClaim\": {\"claimName\": \"shared\"}\n",
    "            }],\n",
    "            containers=[{\n",
    "                \"name\": \"node\",\n",
    "                \"volumeMounts\": [{\"name\": \"shared\", \"mountPath\": \"/shared\"}],\n",
    "                \"env\": [\n",
    "                    {\"name\": \"TRAINING_MODE\", \"value\": \"traditional\"},\n",
    "                    {\"name\": \"SDK_VERSION\", \"value\": \"0.2.0.dev0\"}\n",
    "                ]\n",
    "            }]\n",
    "        )\n",
    "    ])\n",
    "]\n",
    "\n",
    "# Submit traditional training job\n",
    "job1_name = trainer_client.train(\n",
    "    trainer=traditional_trainer,\n",
    "    runtime=trainer_client.get_runtime(\"torch-cuda-251\"),\n",
    "    options=traditional_options\n",
    ")\n",
    "\n",
    "print(f\" Traditional TrainJob '{job1_name}' submitted!\")\n",
    "\n",
    "print(\"\\n DEMO 2: Hybrid Training (Function + Container Customization)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Hybrid approach: Function + Option 2 container customization\n",
    "hybrid_trainer = CustomTrainer(\n",
    "    func=main,\n",
    "    func_args={\n",
    "        \"epochs\": 2,  # Quick demo\n",
    "        \"save_every\": 1,\n",
    "        \"batch_size\": 4,\n",
    "        \"backend\": \"gloo\",\n",
    "        \"lr\": 0.001,\n",
    "        \"dataset_path\": \"/tmp/data\",  # Use tmp for demo\n",
    "        \"snapshot_path\": \"/tmp/snapshot_mnist.pt\"\n",
    "    },\n",
    "    num_nodes=1,\n",
    "    resources_per_node={\n",
    "        \"cpu\": \"2\",\n",
    "        \"memory\": \"4Gi\"\n",
    "    },\n",
    "    packages_to_install=[\"torchvision\"]\n",
    ")\n",
    "\n",
    "# Hybrid options: Traditional + Option 2 features\n",
    "hybrid_options = [\n",
    "    WithName(\"mnist-hybrid-demo\"),\n",
    "    WithLabels({\n",
    "        \"approach\": \"hybrid\",\n",
    "        \"has-function\": \"true\",\n",
    "        \"has-container-customization\": \"true\"\n",
    "    }),\n",
    "    WithAnnotations({\n",
    "        \"description\": \"Hybrid training with function + container customization\"\n",
    "    }),\n",
    "    \n",
    "    #  Option 2: Container customization\n",
    "    WithTrainerImage(\"python:3.11\"),  # Custom base image\n",
    "    WithTrainerCommand([\"python\", \"-u\"]),  # Unbuffered output\n",
    "    WithTrainerArgs([\"-c\", \"print('ðŸ”§ Custom container initialized'); import runpy; runpy.run_module('__main__', run_name='__main__')\"])\n",
    "]\n",
    "\n",
    "# Submit hybrid training job\n",
    "job2_name = trainer_client.train(\n",
    "    trainer=hybrid_trainer,\n",
    "    runtime=trainer_client.get_runtime(\"torch-cuda-251\"),\n",
    "    options=hybrid_options\n",
    ")\n",
    "\n",
    "print(f\" Hybrid TrainJob '{job2_name}' submitted!\")\n",
    "\n",
    "print(\"\\n DEMO 3: Container-Only Training (No Python Function)\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Container-only approach: No Python function required\n",
    "container_trainer = CustomTrainer(\n",
    "    # No func parameter - this is container-only training\n",
    "    num_nodes=1,\n",
    "    resources_per_node={\n",
    "        \"cpu\": \"1\",\n",
    "        \"memory\": \"2Gi\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Container-only options: Pure Option 2\n",
    "container_options = [\n",
    "    WithName(\"mnist-container-only-demo\"),\n",
    "    WithLabels({\n",
    "        \"approach\": \"container-only\",\n",
    "        \"has-function\": \"false\",\n",
    "        \"option\": \"2\"\n",
    "    }),\n",
    "    WithAnnotations({\n",
    "        \"description\": \"Container-only training without Python functions\"\n",
    "    }),\n",
    "    \n",
    "    # ðŸ³ Option 2: Full container control\n",
    "    WithTrainerImage(\"python:3.11\"),\n",
    "    WithTrainerCommand([\"python\", \"-c\"]),\n",
    "    WithTrainerArgs([\n",
    "        \"import os, time; \"\n",
    "        \"print(' Hello from container-only training!'); \"\n",
    "        \"print(f' Node: {os.environ.get(\\\"HOSTNAME\\\", \\\"unknown\\\")}'); \"\n",
    "        \"print(f' Rank: {os.environ.get(\\\"RANK\\\", \\\"0\\\")}'); \"\n",
    "        \"print(' Container-only training completed!'); \"\n",
    "        \"time.sleep(30)\"  # Keep running for demo\n",
    "    ])\n",
    "]\n",
    "\n",
    "# Submit container-only training job\n",
    "job3_name = trainer_client.train(\n",
    "    trainer=container_trainer,\n",
    "    runtime=trainer_client.get_runtime(\"torch-cuda-251\"),\n",
    "    options=container_options\n",
    ")\n",
    "\n",
    "print(f\"Container-only TrainJob '{job3_name}' submitted!\")\n",
    "\n",
    "print(\"\\n ALL DEMOS SUBMITTED SUCCESSFULLY!\")\n",
    "print(\"=\" * 40)\n",
    "print(f\" Jobs created:\")\n",
    "print(f\"  1. Traditional: {job1_name}\")\n",
    "print(f\"  2. Hybrid: {job2_name}\")\n",
    "print(f\"  3. Container-only: {job3_name}\")\n",
    "\n",
    "# Store job names for monitoring\n",
    "job_names = [job1_name, job2_name, job3_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b614dd6-3669-4503-9da0-5097b781e61c",
   "metadata": {},
   "source": [
    "### Monitor Multiple Training Jobs\n",
    "\n",
    "Monitor all three training approaches and compare their behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ab1733-eb5d-45c0-8751-19a2bf3d2431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring job status...\n",
      "Job Status: Running\n",
      "Created: 2025-10-05 16:07:43+00:00\n",
      "Runtime: torch-cuda-251\n",
      "Steps:\n",
      "  - node-0: Running\n",
      "  - node-1: Running\n",
      "\n",
      "Job is now: Running\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Get job status\n",
    "def get_job_status():\n",
    "    try:\n",
    "        job = trainer_client.get_job(job_name)\n",
    "        print(f\"Job Status: {job.status}\")\n",
    "        print(f\"Created: {job.creation_timestamp}\")\n",
    "        print(f\"Runtime: {job.runtime.name}\")\n",
    "        \n",
    "        if job.steps:\n",
    "            print(\"Steps:\")\n",
    "            for step in job.steps:\n",
    "                print(f\"  - {step.name}: {step.status}\")\n",
    "        \n",
    "        return job.status\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting job status: {e}\")\n",
    "        return None\n",
    "\n",
    "# Monitor job status\n",
    "print(\"Monitoring job status...\")\n",
    "status = get_job_status()\n",
    "\n",
    "# Wait for job to start\n",
    "while status in [\"Pending\", \"Starting\", None]:\n",
    "    print(\"Waiting for job to start...\")\n",
    "    time.sleep(10)\n",
    "    status = get_job_status()\n",
    "\n",
    "print(f\"\\nJob is now: {status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf62a15a-3202-4239-a7bf-39b466a8c852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get training logs\n",
    "try:    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TRAINING LOGS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Get logs from the training nodes\n",
    "    logs = trainer_client.get_job_logs(job_name, follow=False)\n",
    "    \n",
    "    # Display logs - logs is a generator\n",
    "    log_count = 0\n",
    "    for log_line in logs:\n",
    "        if log_line.strip():\n",
    "            print(log_line)\n",
    "            log_count += 1\n",
    "            # Limit output for demo purposes\n",
    "            if log_count > 100:\n",
    "                print(\"\\n... (truncated for demo) ...\")\n",
    "                break\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error getting logs: {e}\")\n",
    "    print(\"Note: Logs may not be available yet if training is still starting up\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30f3c09-cffe-467d-b48e-b1c43a529b4c",
   "metadata": {},
   "source": [
    "### Cleanup Resources and Summary\n",
    "\n",
    "Clean up all training jobs and summarize the new SDK features demonstrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c3f19c-5aba-4738-8ba2-32a3dc6b15b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final TrainJob Status:\n",
      "   Name: v50712dfc954\n",
      "   Status: Running\n",
      "   Created: 2025-10-05 16:16:01+00:00\n",
      "   Nodes: 2\n",
      "   Runtime: torch-cuda-251\n",
      "   Steps:\n",
      "     - node-0: Running\n",
      "     - node-1: Running\n",
      "âœ“ TrainJob 'v50712dfc954' deleted successfully\n",
      "\n",
      "================================================================================\n",
      "DEMO COMPLETE\n",
      "================================================================================\n",
      "This notebook demonstrated:\n",
      "âœ“ Creating TrainJobs programmatically with Kubeflow SDK\n",
      "âœ“ Replicating trl_training.yaml functionality\n",
      "âœ“ Distributed TRL training with checkpointing\n",
      "âœ“ Real-time monitoring and logging\n",
      "âœ“ Advanced progression tracking\n",
      "\n",
      "To cleanup: Uncomment the cleanup_trainjob() call above\n"
     ]
    }
   ],
   "source": [
    "def cleanup_trainjob():\n",
    "    \"\"\"Clean up the TrainJob using Kubeflow SDK\"\"\"\n",
    "    try:\n",
    "        trainer_client.delete_job(job_name)\n",
    "        print(f\"âœ“ TrainJob '{job_name}' deleted successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting TrainJob: {e}\")\n",
    "\n",
    "# Get final job status before cleanup\n",
    "try:\n",
    "    final_job = trainer_client.get_job(job_name)\n",
    "    print(f\"Final TrainJob Status:\")\n",
    "    print(f\"   Name: {final_job.name}\")\n",
    "    print(f\"   Status: {final_job.status}\")\n",
    "    print(f\"   Created: {final_job.creation_timestamp}\")\n",
    "    print(f\"   Nodes: {final_job.num_nodes}\")\n",
    "    print(f\"   Runtime: {final_job.runtime.name}\")\n",
    "    \n",
    "    if final_job.steps:\n",
    "        print(f\"   Steps:\")\n",
    "        for step in final_job.steps:\n",
    "            print(f\"     - {step.name}: {step.status}\")\n",
    "    \n",
    "    # Uncomment to automatically cleanup completed jobs\n",
    "    # if final_job.status in [\"Complete\", \"Failed\"]:\n",
    "    cleanup_trainjob()\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error getting final job status: {e}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
